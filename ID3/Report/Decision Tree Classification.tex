\documentclass{article}
\linespread{1.25}

\usepackage[top = 2cm, right=2cm, left=2cm]{geometry}
\usepackage{graphicx}
\usepackage[section]{placeins}
\usepackage[hidelinks, urlcolor=blue]{hyperref}
\usepackage{float} % for image position in exatly where you want
\usepackage[perpage, stable]{footmisc}
\usepackage{amsmath}
\usepackage{titling}

\usepackage{xepersian}
\settextfont{B Nazanin}
\setlatinmonofont{CMU Serif}
%\setlatinmonofont{Times New Roman}
\setlatintextfont{Times New Roman}

% Set Latin Modern font for the bullets in itemizea
\newfontfamily\latinbullet{Latin Modern Roman}





% Commands
\newcommand{\column}[1]{\lr{\textit{#1}}}
\renewcommand{\labelitemi}{{\latinbullet\textbullet}} % Use the bullet from Latin Modern font

% Custom title page setup
\makeatletter
\def\maketitle{
	\begin{titlepage}
		\begin{center}
			\vspace*{2cm}
			
			{\Large\bfseries درس یادگیری ماشین\par}
			\vspace{2cm}
			
			{\Huge\bfseries گزارش تکلیف
				 \lr{Decision Tree}\par}
			\vspace{3cm}
			
			{\large\bfseries استاد درس:\par}
			{\large دکتر افتخاری\par}
			\vspace{1.5cm}
			
			{\large\bfseries نگارش:\par}
			{\large امیرحسین ابوالحسنی\par}
			{\large شماره دانشجویی: 400405003\par}
			\vspace{2cm}
			
			\vfill  % pushes the date to bottom
			
			{\large\bfseries پاییز \lr{1403}}
			
		\end{center}
	\end{titlepage}
	\setcounter{page}{1}
}
\makeatother


\begin{document}
	\maketitle	
	\tableofcontents
	\newpage
	\section{مقدمه}
	درخت تصمیم گیری یک مدل یادگیری نظارت شده است که به طور گسترده ای در مسائل طبقه‌بندی مورد استفاده قرار می‌گیرد.
	الگوریتم \lr{ID3} یکی از پرکاربرد ترین الگوریتم‌های ساخت درخت تصمیم می باشد. این الگوریتم با استفاده از معیار انتروپی
	\footnote{\lr{Entropy}}
	بهترین ویژگی را برای تقسیم گره انتخاب می کند و به طور بازگشتی این فرایند را تا زمان رسیدن به یکی از شرط‌های پایه انجام می‌دهد.\\
	در این گزارش، ابتدا به بررسی دیتاست و پیش پردازش های روی آن پرداخته می‌شود، سپس توضیحی درباره شیوه 
	\lr{Feature Selection}
	داده می‌شود و در نهایت، نتایج هر درخت روی زیرمجموعه‌ای از ویژگی‌ها بررسی می گردد.
	
	\section{بررسی دیتاست}
	\subsection{آشنایی با ویژگی‌ها}
	در این تکلیف دیتاست با نام 
	\lr{Salary}
	مورد استفاده قرار می‌گیرد. این دیتاست متشکل از 32561 نمونه، 15 ویژگی افراد را همراه با کلاس درامد سالانه‌شان ثبت کرده است.
	
	\begin{table}[h]
		\centering
		\begin{tabular}{|c|c|c|c|}
			\hline
			نام ویژگی &‌ نوع ویژگی & تعداد مقادیر یکتا & نمونه مقدار\\
			\hline
			\hline
			\column{age} & عددی &  & 50\\
			\hline
			\column{workclass} & گسسته & 9 & \lr{Federal-gov}\\
			\hline
			\column{fnlwgt} & عددی &  & 77516\\
			\hline
			\column{education} & گسسته & 16 & \lr{HS-grad}\\
			\hline
			\column{education-num} & گسسته & 16 & 3\\
			\hline
			\column{marital-status} & گسسته & 7 & \lr{Married-spouse-absent}\\
			\hline
			\column{occupation} & گسسته & 15 & \lr{Tech-support}\\
			\hline
			\column{relationship} & گسسته & 6 & \lr{Wife}\\
			\hline
			\column{race} & گسسته & 5 & \lr{White}\\
			\hline
			\column{sex} & گسسته & 2 & \lr{Male}\\
			\hline
			\column{capital-gain} & عددی &  & 10566\\
			\hline
			\column{capital-loss} & عددی &  & 974\\
			\hline
			\column{hours-per-week} & عددی &  & 88\\
			\hline
			\column{native-country} & 4گسسته & 2 & \lr{England}\\
			\hline
			\column{salary} & 2گسسته & 2 & \lr{<=50K, >50K}\\
			\hline
		\end{tabular}
		\caption{ویژگی‌های دیتاست \lr{salary}}
	\end{table}
	\subsection{مقادیر هیچ مقدار}
	خوشبختانه این دیتاست داری هیج مقدار گم شده‌ای نمی‌باشد.
	\newpage
	\subsection{نمودار‌ها}
	توزیع برخی ویژگی‌ها در دیتاست برسی شده است.\\
	همانطور که در نمودار 
	\ref{fig: sex dist}
	می‌توان دید، جمعیت مردان دو برابر جمعیت زنان در این دیتاست می باشد.
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{figs/sex_dist}
		\caption{
			توزیع ویژگی 
			\lr{Sex}
		}
		\label{fig: sex dist}
	\end{figure}
			یکی از ویژگی‌های دیگر، نژاد هر نمونه در دیتاست می‌باشد، همانطور که در نمودار
			\ref{fig: race dist}
			 مشاهده می شود، افراد سفید پوست بیشترین افراد و افراد هندی-اسکیمو کمترین نژاد مشخص در این دیتاست هستند.
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{figs/Race_dist}
		\caption{
			توزیع ویژگی 
			\lr{Race}
		}
		\label{fig: race dist}
	\end{figure}
	یکی از مهمترین توزیع‌های این دیتاست، توزیع متغیر 
	\lr{Age}
	می‌باشد. همانظور که در نمودار 
	\ref{fig: age dist}
	مشاهده می‌شود، بیشتر نمونه‌ها در 30 تا 40 سالگی خود قرار دارند. و همچنین افراد زیر 10 سال و بالای 90 سال عضویت بسیار کمی در این دیتاست دارند.\\
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{figs/age_dist}
		\caption{
			توزیع ویژگی 
			\lr{Age}
		}
		\label{fig: age dist}
	\end{figure}
	همچنین توزیع ویژگی‌های افزایش سرمایه و کاهش سرمایه را در نمودارهای 
	\ref{fig: captial gain}
	و
	\ref{fig: captial loss}
	 می‌توان بررسی کرد. با توجه به ارتباط مالی با موضوع به نظر می‌رسد ویژگی‌های مرتبطی به تارگت باشند.
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{figs/capital_gain_dist}
		\caption{
			توزیع ویژگی 
			\lr{Capital Gain}
		}
		\label{fig: captial gain}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{figs/capital_loss_dist}
		\caption{
			توزیع ویژگی 
			\lr{Capital Loss}
		}
		\label{fig: captial loss}
	\end{figure}
	یکی دیگر از ویژگی‌های مهم سطح تحصیلات فرد است که در کشور‌هایی که روابط منطق تا حد قابل قبولی در آن برقرار است! ، معمولا افرادی که سطح بالاتری از تحصیلات را دارا هستند جزو افرادی هستند که درامد خوبی دارند (نمودار 
	\ref{fig: salary by education dist}
	)،‌ هرچند عکس این مورد صحیح نمی‌باشد.\\
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{figs/education_dist}
		\caption{
			توزیع ویژگی 
			\lr{Education}
		}
		\label{fig: education dist}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{figs/salary_by_edu}
		\caption{
			توزیع ویژگی 
			\lr{Salary}
			بر اساس
			\lr{Education}
		}
		\label{fig: salary by education dist}
	\end{figure}
	همچنین توزیع ساعت کار روزانه نمونه‌ها در نمودار 
	\ref{fig: hours dist}
	نشان داده شده است.\\
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{figs/hours_dist}
		\caption{
			توزیع ویژگی 
			\lr{Hours Per Week}
		}
		\label{fig: hours dist}
	\end{figure}
	از دیگر ویژگی‌های تقریبا مرتبط می‌توان به نوع شغل افراد اشاره کرد که توزیع آن در نمودار 
	\ref{fig: occ dist}
	نشان داده شده است.\\
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{figs/occupation_dist}
		\caption{
			توزیع ویژگی 
			\lr{Occupation}
		}
		\label{fig: occ dist}
	\end{figure}
	یکی از ویژگی‌های کلیدی که بعدا توسط درخت به دست می‌آید، ویژگی 
	\lr{Relationship}
	می باشد.(نمودار 
	\ref{fig: relationship dist}
	)
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{figs/relationship_dist}
		\caption{
			توزیع ویژگی 
			\lr{Relationship}
		}
		\label{fig: relationship dist}
	\end{figure}
	در انتها برای جمع بندی نمودارها سعی شده توزیع کلاس‌های ویژگی هدف بررسی شود. همانطور که مشاهده می‌شود، دیتا ست به هیچ وجه بالانس نمی‌باشد و داده‌های کلاس ‌مینور
	\footnote{\lr{Minor}}
	مربوط به کلاس درامد بالاتر می‌باشد.\\
	همچمنین در نمودار
	\ref{fig: salary grouped}
	توزیع کلاس هدف با توجه به سه ویژگی نشان داده شده تا درک بهتری از رابطه هر ویژگی با هر کلاس ویژگی هدف به دست بیاید.
	
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.3]{figs/Salary_grouped_dist}
		\caption{
			توزیع ویژگی 
			\lr{Salary}
			طبق ویژگی‌های 
			\lr{Occupation, Relationship, Sex}
		}
		\label{fig: salary grouped}
	\end{figure}
	\FloatBarrier
	\subsection{دسته بندی ویژگی‌ها}
	برای کار با درخت تصمیم نیاز به این است که داده‌ها گسسته باشند. با تعیین بازه‌هایی، ویژگی‌های 
	\lr{Age, Hours per Week, Capital Gain}
	گسسته سازی شدند.\\
	در جداول
	\ref{tbl: age}
	و
	\ref{tbl: hours/week}
	و
	\ref{tbl: capital gain}
	مقادیر هر ویژگی و بازه‌های گسسته‌سازی نشان داده شده است.
	\begin{table}[H]
		\centering
			\begin{tabular}{|c|c|c|}
				\hline
				$(50, \infty)$ & $(30, 50]$ & $(0, 30]$\\
				\hline
				\lr{Over 50} & 31 - 50 & 1 - 30\\
				\hline
			\end{tabular}
			\caption{گسسته سازی 
				\lr{Age}
			}
			\label{tbl: age}
	\end{table}
	\begin{table}[H]
		\centering
		\begin{tabular}{|c|c|c|c|}
			\hline
			$(60, \infty)$ & $(40, 60]$ & $(20, 40]$ & $(0, 20]$\\
			\hline
			\lr{Very High} & \lr{High} & \lr{Average} & \lr{Low}\\
			\hline
		\end{tabular}
		\caption{گسسته سازی 
			\lr{$\frac{\text{Hours}}{\text{Week}}$}
		}
		\label{tbl: hours/week}
	\end{table}
	\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		$(15000, \infty)$ & $(0, 15000]$\\
		\hline
		\lr{>15K} & \lr{<=15K}\\
		\hline
	\end{tabular}
	\caption{گسسته سازی 
		\lr{Capital Gain}
	}
	\label{tbl: capital gain}
\end{table}	

\subsection{حذف دستی برخی ویژگی‌ها}
در اینحا به علل حذف سه ویژگی 
\lr{fnlwgt}
و
\lr{education-num}
و
\lr{capital-loss}
اشاره میگردد.
\begin{itemize}
	\item \lr{education-num}:
	 این ویژگی بدین علت که با ویژگی
	 \lr{Education}
	 یکی است. باعث ایجاد افزونگی می‌شود.
	\item \lr{capital-loss}:
	با نگاه به نمودار 
	\ref{fig: captial loss}
	می‌توان استنتاج کرد که حجم ضرری که افراد متحمل شدند آنقدر زیاد نیست که در درآمد سالانه آنها تاثیر بگذارد، اما بالعکس، حجم \lr{capital gain} با توجه به اینکه در یکسری افراد، خیلی بالاست، قابل تاثیر گذاری در درآمد سالانه فرد می‌باشد.
\end{itemize}
	
	\section{
		انتخاب ویژگی
		\footnote{\lr{Feature Selection}}
		‌}
	برای این بخش، از معیاری به نام آزمون کای-دو
	\footnote{\lr{Chi Square Test}}
	برای انتخاب مجموعه از از ویژگی‌ها که بیشترین ارتباط را با متغیر هدف دارند، استفاده شده است.\\
	آزمون کای-دو یکی از روش‌های آماری پرکاربرد است که برای تحلیل داده‌های کیفی و بررسی روابط بین متغیرهای گسسته استفاده می‌شود. این آزمون به طور گسترده در حوزه‌های مختلف از جمله یادگیری ماشین، تحلیل داده و تحقیقات علمی مورد استفاده قرار می‌گیرد.
	در زمینه انتخاب ویژگی در درخت تصمیم و الگوریتم
	 \lr{ID3}
	 ، آزمون کای-دو برای اندازه‌گیری میزان وابستگی بین ویژگی‌ها و متغیر هدف استفاده می‌شود. این آزمون به ما کمک می‌کند تا تشخیص دهیم کدام ویژگی‌ها ارتباط قوی‌تری با متغیر هدف دارند.
	 \footnote{
	 	توضیحات مربوط به آزمون کای-دو توسط مدل
	 	\lr{Claude}
	 	نوشته شده است.
	 }\\
	 فرمول آزمون-کای-دو به صورت زیر است:
	 \[
	 \chi^{2} = \sum \frac{(O_i - E_i)^2}{E_i}
	 \]
	 مقدار معیار کای-دو هر ویژگی در جدول
	 \ref{tbl: chi2 vals}	 
	 قابل مشاهده است.
	 \begin{table}[H]
		\centering	 	
	 	\begin{tabular}{|c|c|}
	 		\hline
	 		ویژگی & $\chi^2$\\
	 		\hline
	 		\column{Relationship} & 3659\\
	 		\hline
	 		\column{Capital Gain} & 1866\\
	 		\hline
	 		\column{Marital Status} & 1123\\
	 		\hline
	 		\column{Age} & 1113\\
	 		\hline
	 		\column{Occupation} & 504\\
	 		\hline
	 		\column{Sex} & 502\\
	 		\hline
	 		\column{Education} & 297\\
	 		\hline
	 		\column{Hours per Week} & 199\\
	 		\hline
	 		\column{Work class} & 47\\
	 		\hline
	 		\column{Race} & 33\\
	 		\hline
	 		\column{Native Country} & 13\\
	 		\hline
	 	\end{tabular}
	 	\caption{مقادیر 
	 		$\chi^2$
	 		برای هر ویژگی
	 	}
	 	\label{tbl: chi2 vals}
	 \end{table}
	\section{آموزش مدل}\label{sec: train}
	قبل از آموزش مدل، با تغییری در کد تابع 
	\lr{id3}
	قابلیت هرس کرن بر اساس یک آستانه برای 
	\lr{Information Gain}
	را در تابع ایجاد کردیم.‌ این به مدل کمک می‌کند تا از بیش برازش
	\footnote{\lr{Overfit}}
	جلوگیری کند. همچنین باعث کم شدن عمق درخت می‌شود که در نهایت به پیچیدگی حافظه درخت نیز کمک خواهد کرد.\\
	\subsection{تقسیم دیتاست}
	برای اینکه فاز 
	\lr{Evaluation}
	عادلانه باشد، دیتاست به دو بخش 
	\lr{Train ( $80\%$ )}
	و
	\lr{Test ( $20\%$ )}
	تقسیم می‌شود.\\
	\subsection{آموزش مدل روی همه ویژگی‌ها}
	برای داشتن یک پایه برای مقایسه، ابتدا درخت را روی همه ویژگی‌ها آموزش می‌دهیم. همچنین برای دیدن تاثیر تغییر آستانه
	\lr{Information Gain}
	،(و به نوعی تاثیر بیش‌برازش در دقت و 
	\lr{F1 Score}
	) در هر مرحله این مقدار را از 0 به 2.0 با قدم‌های 02.0 برده شده است.(شکل 
	\ref{fig: ig all train}
	و
	\ref{fig: ig all train2}
	)
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.3]{figs/all_feature_train1}
		\caption{
			نمودار‌های 
			\lr{Accuracy, F1 Score, Precision \& Recall}
			با توجه به مقدار آستانه
			\lr{Information Gain}
		}
		\label{fig: ig all train}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.3]{figs/all_feature_train2}
		\caption{
			نمودار‌های 
			\lr{Inference Time}
			و ارتفاع درخت،
			با توجه به مقدار آستانه
			\lr{Information Gain}
		}
		\label{fig: ig all train2}
	\end{figure}
	\subsection{آموزش مدل روی 4 ویژگی}
	پس از اینکه با استفاده از معیار 
	$\chi^2$
	،‌ویژگی‌ها را طبقه‌بندی کردیم. در این بخش چهار تا از بهترین ویژگی‌ها را انتخاب کرده و با آنها درخت تصمیم جدید را تشکیل می‌دهیم. در شکل 
	\ref{fig: ig 4 train}
	و
	\ref{fig: ig 4 train2}
	نمودار‌های مختلف روی مقادیر مختلف آستانه
	\lr{Information Gain}
	نشان داده می‌شود.
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.3]{figs/4_feature_train1}
		\caption{
			نمودار‌های 
			\lr{Accuracy, F1 Score, Precision \& Recall}
			با توجه به مقدار آستانه
			\lr{Information Gain}
		}
		\label{fig: ig 4 train}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.3]{figs/4_feature_train2}
		\caption{
			نمودار‌های 
			\lr{Inference Time}
			و ارتفاع درخت،
			با توجه به مقدار آستانه
			\lr{Information Gain}
		}
		\label{fig: ig 4 train2}
	\end{figure}
	\subsection{آموزش مدل روی 8 ویژگی}
	اینبار هشت تا از بهترین ویژگی‌ها را انتخاب کرده و با آنها درخت تصمیم جدید را تشکیل می‌دهیم. در شکل 
	\ref{fig: ig 8 train}
	و
	\ref{fig: ig 8 train2}
	نمودار‌های مختلف روی مقادیر مختلف آستانه
	\lr{Information Gain}
	نشان داده می‌شود.
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.3]{figs/8_feature_train1}
		\caption{
			نمودار‌های 
			\lr{Accuracy, F1 Score, Precision \& Recall}
			با توجه به مقدار آستانه
			\lr{Information Gain}
		}
		\label{fig: ig 8 train}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.3]{figs/8_feature_train2}
		\caption{
			نمودار‌های 
			\lr{Inference Time}
			و ارتفاع درخت،
			با توجه به مقدار آستانه
			\lr{Information Gain}
		}
		\label{fig: ig 8 train2}
	\end{figure}
	\section{نتایج}
	 نمره‌های بهترین مدل‌های بخش 
	\lr{\ref{sec: train}}
	در جدول 
	\ref{table: comp scores}
	جمع آوری شده است.
	\begin{table}[H]
		\centering
		\begin{tabular}{|c|c|c|c|c|c|c|c|}
			\hline
			متد‌ استفاده شده &‌ آستانه \lr{IG} & ارتفاع &($\times 10^{-5}$) زمان استنتاج  &  دقت &
			\lr{Precision} &
			\lr{Recall} &
			\lr{F1 Score}\\
			\hline
			\hline
			- & 12.0 & 7 & 8.0 & 81.0 & 73.0 & 40.0 & 52.0\\
			\hline
			$\chi^2$ - بهترین 8 تا &1.0
			& 6 & 88.0 & 81.0 & 72.0 & 41.0 & 53.0\\
			\hline
			$\chi^2$ - بهترین 4 تا &
			 0 & 4 & 2 & 77.0 & 74.0 & 13.0 & 22.0\\
			\hline
		\end{tabular}
		\caption{جدول مقایسه نمره‌های بهترین مدل‌ها}
		\label{table: comp scores}
	\end{table}
	
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.6]{figs/confall}
		\caption{
			ماترس سردرگمی
			 درخت معمولی
		}
		\label{fig: conf all}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.6]{figs/conf8}
		\caption{
			ماترس سردرگمی
			درخت ساخته شده با 8 ویژگی
		}
		\label{fig: conf 8}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.6]{figs/conf4}
		\caption{
			ماترس سردرگمی
			درخت ساخته شده با 4 ویژگی
		}
		\label{fig: conf 4}
	\end{figure}
	\section{نتیجه گیری}
	همانطور که در جدول 
	\ref{table: comp scores}
	دیده می‌شود، در این دیتاست دقت با کمتر شدن تعداد فیچر‌ها بعد از 8 ویژگی افت می‌کند، همچنین 
	\lr{F1 Score}
	ابتدا سیر صعودی گرفته اما در 4 ویژگی به شدت کاهش پیدا می‌کند.\\
	می‌توان از جدول 
	\ref{table: comp scores}
	نتیجه گرفت مدلی که با 8 ویژگی اول جدول
	\ref{tbl: chi2 vals}
	و با آستانه 
	\lr{IG}
	برابر با 1.0 آموزش ببیند، بهترین عملکرد را خواهد داشت.\\
	یکی از تفسیر‌ها برای مقدار کم 
	\lr{Recall}
	می‌تواند بالانس نبودن داده‌ها باشد. فرمول 
	\lr{Recall}
	بدین صورت است:
	\[
												Recall = \frac{TP}{TP + FN}
	\]
	زمانی که داده‌ها بالانس نباشد و کلاس میینور کلاس مثبت باشد، بایاس روی مقادیر کلاس منفی اتفاق می افتد و باعث می‌شود خیلی از نمونه‌ها منفی گزارش شوند، حتی اگر متعلق به کلاس مثبت باشند.(شکل
	\ref{fig: conf 4}
	و
	\ref{fig: conf 8}
	و
	\ref{fig: conf all}
	) این باعث می‌شود مقدار $False~Negative$ بالا برود و با این اتفاق، 
	مقدار 
	\lr{Recall}
	کم بشود.
	\section{
    کنجکاوی: مصورسازی دیتاست با
		\lr{PCA}
		\footnote{\lr{Principle Component Analysis}}
	}
	هرچند این مورد در توضیحات تکلیف ذکر نشده است اما حقیقتا مبحث \textit{کاهش ابعاد}
	\footnote{\lr{Dimensionality Reduction}}
	همیشه باعث شگفتی است!\\
	 در شکل 
	 \ref{fig: pca 2}
	 دیده می‌شود که اگر 
	 \lr{PCA}
	 با دو مولفه اصلی انجام شود، جز معدودی از داده‌های کلاس مثبت، قابل جداسازی از داده‌های کلاس منفی نیستند.\\
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{figs/pca2}
		\caption{
			نمودار پراکندگی داده‌ها پس از انجام
			\lr{PCA}
			با دو مولفه
		}
		\label{fig: pca 2}
	\end{figure} 
	اما با 3 مولفه، می‌توان در شکل
	\ref{fig: pca 3}
	 دید که جداپذیری داده‌های هر کلاس بالاتر میرود، انگار که وجه دیگری از داده به نمایش گذاشته می‌شود.
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.5]{figs/pca3}
		\caption{
			نمودار پراکندگی داده‌ها پس از انجام
			\lr{PCA}
			با سه مولفه
		}
		\label{fig: pca 3}
	\end{figure} 
\end{document}